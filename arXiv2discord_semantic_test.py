# FILE: main.py (versione corretta)

import os
import re
import subprocess
import requests
import logging
from datetime import datetime, timezone
from bs4 import BeautifulSoup

# --- Configurazione Globale ---
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

# URL e Webhook
ARXIV_URL = "https://arxiv.org/list/astro-ph.GA/new"
DISCORD_WEBHOOK = os.getenv("DISCORD_WEBHOOK")

# Configurazione LLM da variabili d'ambiente
LLAMA_BIN = os.getenv("LLAMA_BIN", "./llama.cpp/build/bin/llama-cli")
LLM_MODEL_PATH = os.getenv("LLM_MODEL_PATH")
SEED = int(os.getenv("SEED", "42"))
MAX_TOKENS_SUMMARY = int(os.getenv("MAX_TOKENS_SUMMARY", "2048"))
CTX_SIZE = int(os.getenv("CTX_SIZE", "8192"))

# --- Interessi scientifici per la pre-selezione ---
SCIENTIFIC_INTERESTS = """
My core research interests are:
- Active Galactic Nuclei (AGN) physics, including accretion, feedback, and outflows.
- The co-evolution of supermassive black holes (SMBHs) and their host galaxies.
- Galaxy evolution, particularly galaxy mergers, morphology, and quenching processes.
- Emission line diagnostics (e.g., BPT diagrams), photoionization modeling, and metallicity studies.
- Connections between AGN activity and star formation in galaxies.
"""

# --- Prompt Templates ---
SELECTION_PROMPT_TEMPLATE = f"""
You are an expert astrophysicist assistant. Your task is to select the 5 most relevant paper titles from a list based on specific research interests.

<Interests>
{SCIENTIFIC_INTERESTS}
</Interests>

Here is the list of today's new paper titles from arXiv astro-ph.GA:
<Titles>
{{paper_list}}
</Titles>

Task: Identify the 5 titles that are most semantically aligned with the interests described above.
Respond with ONLY the paper numbers, separated by commas (e.g., "1, 3, 5, 7, 9"). Do not add any other text or explanation.
"""

SUMMARY_PROMPT_TEMPLATE = """
You are an expert astrophysicist. Your task is to provide concise, technical summaries of selected arXiv papers for a research group.

Here are the selected papers for today ({date_utc}):
{paper_block}

Your task is twofold:

1.  For EACH of the {paper_count} papers provided, write a summary in exactly this format:
    **Paper: [Title]**
    Authors: [First Author et al.]
    Link: [arXiv URL]
    Summary: [A concise 2-3 sentence summary of the abstract. Focus on methods, key results, and significance for galaxy evolution or AGN research.]

2.  After summarizing all papers, add a final overview paragraph in this format:
    **Daily Highlights:**
    [A brief synthesis of today's key findings. Connect the themes of the selected papers if possible. What are the most notable results or trends today?]
"""

# --- Funzioni Principali ---

def fetch_and_parse_arxiv():
    """
    Esegue lo scraping della pagina arXiv e estrae i dati dei paper,
    ignorando cross-listing e replacement.
    """
    logging.info(f"1. Fetching data from {ARXIV_URL}...")
    try:
        response = requests.get(ARXIV_URL, timeout=30, headers={"User-Agent": "Mozilla/5.0"})
        response.raise_for_status()
    except requests.RequestException as e:
        logging.error(f"Failed to fetch arXiv page: {e}")
        return []

    logging.info("Parsing HTML content...")
    soup = BeautifulSoup(response.text, "lxml")
    
    # Seleziona solo la sezione "New submissions"
    new_submissions_header = soup.find('h3', string=re.compile(r'New submissions'))
    if not new_submissions_header:
        logging.warning("Could not find the 'New submissions' section header.")
        return []
        
    # --- INIZIO CODICE MODIFICATO ---
    # Cerca il primo tag <dl> che segue l'intestazione, ignorando altri tag intermedi.
    # Questo √® molto pi√π robusto di find_next_sibling().
    dl_element = None
    for sibling in new_submissions_header.find_next_siblings():
        if sibling.name == 'dl':
            dl_element = sibling
            break
        if sibling.name == 'h3':
            # Se incontriamo il prossimo h3 (es. "Cross-lists"), ci fermiamo.
            break
    # --- FINE CODICE MODIFICATO ---

    if not dl_element:
        logging.warning("Could not find the list of papers (<dl> tag) after the 'New submissions' header.")
        return []

    papers = []
    for dt, dd in zip(dl_element.select("dt"), dl_element.select("dd")):
        link_tag = dt.select_one("a[href*='/abs/']")
        if not link_tag:
            continue

        title_tag = dd.select_one("div.list-title")
        authors_tag = dd.select_one("div.list-authors")
        abstract_tag = dd.select_one("p.mathjax")

        # Estrai il primo autore
        authors_text = authors_tag.get_text(" ", strip=True).replace("Authors:", "").strip() if authors_tag else ""
        first_author = authors_text.split(",")[0].strip() if authors_text else "N/A"

        papers.append({
            "title": title_tag.get_text(" ", strip=True).replace("Title: ", ""),
            "first_author": first_author,
            "link": "https://arxiv.org" + link_tag.get("href"),
            "abstract": abstract_tag.get_text(" ", strip=True).strip() if abstract_tag else ""
        })
    
    logging.info(f"Found {len(papers)} new papers.")
    return papers

def select_papers_with_llm(papers):
    """
    Usa l'LLM per selezionare i 5 paper pi√π rilevanti basandosi sui titoli.
    """
    logging.info("2. Starting LLM pre-selection based on titles...")
    if len(papers) <= 5:
        logging.info("Fewer than 6 papers found, selecting all of them.")
        return papers

    # Prepara la lista di titoli per il prompt
    titles_list_str = "\n".join([f"{i+1}. {p['title']}" for i, p in enumerate(papers)])
    prompt = SELECTION_PROMPT_TEMPLATE.format(paper_list=titles_list_str)
    
    # Formato Qwen2
    full_prompt = f"<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n{prompt}<|im_end|>\n<|im_start|>assistant\n"
    
    cmd = [
        LLAMA_BIN, "-m", LLM_MODEL_PATH,
        "-p", full_prompt,
        "-n", "30",              # Pochi token, servono solo numeri
        "-c", "4096",            # Context sufficiente per molti titoli
        "--seed", str(SEED),
        "--temp", "0.1",         # Molto deterministico
        "--no-display-prompt"
    ]

    try:
        result = subprocess.run(cmd, capture_output=True, text=True, timeout=120, check=True)
        output = result.stdout.strip()
        
        # Estrae i numeri in modo robusto
        numbers = re.findall(r'\b(\d+)\b', output)
        selected_indices = {int(n) - 1 for n in numbers if n.isdigit() and 0 < int(n) <= len(papers)}
        
        if len(selected_indices) < 3:
            logging.warning(f"LLM selection returned too few valid indices ({len(selected_indices)}). Output: '{output}'")
            raise ValueError("LLM selection failed.")

        selected_papers = [papers[i] for i in sorted(list(selected_indices))[:5]]
        logging.info(f"LLM selected {len(selected_papers)} papers: {[p['title'][:50]+'...' for p in selected_papers]}")
        return selected_papers

    except (subprocess.TimeoutExpired, subprocess.CalledProcessError, ValueError) as e:
        logging.error(f"LLM selection failed: {e}. Falling back to selecting the first 5 papers.")
        return papers[:5]

def summarize_papers_and_generate_overview(papers):
    """
    Prende i paper selezionati, crea un prompt unico con i loro abstract
    e chiede all'LLM di sintetizzarli e creare un overview.
    """
    logging.info("3. Starting LLM summarization for selected papers...")
    
    # Costruisce il blocco di paper per il prompt
    paper_block_lines = []
    for i, p in enumerate(papers, 1):
        paper_block_lines.append(f"--- Paper {i} ---\nTitle: {p['title']}\nAuthors: {p['first_author']} et al.\nLink: {p['link']}\nAbstract: {p['abstract']}\n")
    paper_block = "\n".join(paper_block_lines)

    date_utc = datetime.now(timezone.utc).strftime("%Y-%m-%d")
    prompt = SUMMARY_PROMPT_TEMPLATE.format(
        date_utc=date_utc,
        paper_block=paper_block,
        paper_count=len(papers)
    )

    full_prompt = f"<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n{prompt}<|im_end|>\n<|im_start|>assistant\n"

    cmd = [
        LLAMA_BIN, "-m", LLM_MODEL_PATH,
        "-p", full_prompt,
        "-n", str(MAX_TOKENS_SUMMARY),
        "-c", str(CTX_SIZE),
        "--seed", str(SEED),
        "--temp", "0.4",
        "--repeat-penalty", "1.1",
        "--no-display-prompt"
    ]

    try:
        logging.info(f"Running summarization with {os.path.basename(LLM_MODEL_PATH)}...")
        result = subprocess.run(cmd, capture_output=True, text=True, timeout=900, check=True) # 15 min timeout
        output = result.stdout.strip()
        
        # Pulizia dell'output
        output = re.sub(r'<\|im_end\|>.*', '', output, flags=re.DOTALL).strip()

        if not output or "**Paper:" not in output:
            raise ValueError("LLM output is empty or malformed.")
            
        logging.info(f"Successfully generated summary of {len(output)} characters.")
        return output

    except (subprocess.TimeoutExpired, subprocess.CalledProcessError, ValueError) as e:
        logging.error(f"LLM summarization failed: {e}")
        return None

def build_fallback_message(papers):
    """Crea un messaggio di fallback se la sintesi LLM fallisce."""
    lines = [f"‚ö†Ô∏è **LLM Summarization Failed!**\n\nHere are the selected papers for today:\n"]
    for p in papers:
        lines.append(f"**- {p['title']}**")
        lines.append(f"  *by {p['first_author']} et al.*")
        lines.append(f"  <{p['link']}>\n")
    return "\n".join(lines)

def post_to_discord(content):
    """Invia il contenuto a Discord, gestendo i messaggi lunghi."""
    if not DISCORD_WEBHOOK:
        logging.warning("DISCORD_WEBHOOK not set. Skipping post.")
        print("\n--- BEGIN DISCORD CONTENT ---\n")
        print(content)
        print("\n--- END DISCORD CONTENT ---\n")
        return

    logging.info("4. Posting message to Discord...")
    
    # Aggiunge un titolo al messaggio
    header = f"### üî≠ Astro-ph.GA Daily Briefing ({datetime.now(timezone.utc).strftime('%d %b %Y')})\n\n"
    content = header + content
    
    max_len = 1950  # Un po' di margine
    chunks = []
    
    if len(content) <= max_len:
        chunks.append(content)
    else:
        # Splitting logic
        current_chunk = ""
        for part in content.split('\n\n'): # Splitta per paragrafi
            if len(current_chunk) + len(part) + 2 > max_len:
                chunks.append(current_chunk)
                current_chunk = part
            else:
                current_chunk += "\n\n" + part if current_chunk else part
        chunks.append(current_chunk)

    for i, chunk in enumerate(chunks):
        payload = {"content": chunk}
        try:
            response = requests.post(DISCORD_WEBHOOK, json=payload, timeout=20)
            response.raise_for_status()
            logging.info(f"Posted chunk {i+1}/{len(chunks)} to Discord successfully.")
        except requests.RequestException as e:
            logging.error(f"Failed to post chunk {i+1} to Discord: {e}")
            if response:
                logging.error(f"Response: {response.text}")
            break


def main():
    """Flusso di lavoro principale."""
    # 0. Verifica prerequisiti
    if not all([DISCORD_WEBHOOK, LLAMA_BIN, LLM_MODEL_PATH]):
        logging.error("Missing critical environment variables. Exiting.")
        return
    if not os.path.exists(LLAMA_BIN) or not os.path.exists(LLM_MODEL_PATH):
        logging.error("LLM binary or model file not found. Exiting.")
        return

    # 1. Scraping
    all_papers = fetch_and_parse_arxiv()
    if not all_papers:
        post_to_discord("No new papers found on astro-ph.GA today.")
        return

    # 2. Selezione con LLM
    selected_papers = select_papers_with_llm(all_papers)
    if not selected_papers:
        post_to_discord("Paper selection failed and no fallback was possible.")
        return

    # 3. Sintesi con LLM
    final_message = summarize_papers_and_generate_overview(selected_papers)
    if not final_message:
        final_message = build_fallback_message(selected_papers)

    # 4. Invio a Discord
    post_to_discord(final_message)
    
    logging.info("Workflow completed successfully.")


if __name__ == "__main__":
    main()
